\documentclass[a4paper,reqno,11pt]{amsart}
\usepackage[T2A]{fontenc}
\usepackage[cp1251]{inputenc}
\usepackage[russian]{babel}
\usepackage{amssymb, amsmath}

\usepackage{geometry}
\geometry{a4paper,top=1.5cm,bottom=1.5cm,left=1.75cm,right=1.75cm}

\righthyphenmin=2
\sloppy

\theoremstyle{plain}
\newtheorem*{theorem}{Теорема}
\theoremstyle{definition}
\newtheorem*{definition}{Определение}
\theoremstyle{remark}
\newtheorem*{example}{Пример}
\newtheorem*{examples}{Примеры}

\DeclareMathOperator{\LCM}{HOK}
\DeclareMathOperator{\HM}{HM}
\DeclareMathOperator{\HT}{HT}
\DeclareMathOperator{\HC}{HC}
\DeclareMathOperator{\len}{len}
\DeclareMathOperator{\Num}{Num}
\DeclareMathOperator{\Mod}{mod}
\newcommand{\M}{\mathbb{M}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\admOrd}{\prec}
\newcommand{\admOrdG}{\succ}
\newcommand{\admOrdLe}{\preccurlyeq}
\newcommand{\admOrdGe}{\succcurlyeq}
\newcommand{\Title}[1]{\emph{#1}}
\renewcommand{\ge}{\geqslant}
\renewcommand{\le}{\leqslant}
\newcommand{\Red}[3]{#1 \xrightarrow[#2]{} #3}

\title[Распараллеливание матричных алгоритмов вычисления базисов Гребнера]{Распараллеливание матричных алгоритмов\\ вычисления базисов Гребнера}
\author{Д. Александров, В. Галкин, А. Зобнин, М. Левин}
\keywords{Базисы Гребнера, алгоритм F4, параллельные алгоритмы, матричная редукция}

\begin{document}

\begin{abstract}
В работе описываются последовательные и параллельные реализации 
алгоритма F4 для построения базисов Гребнера полиномиальных идеалов.
\end{abstract}

\maketitle

\section{Введение}
Задачи исследования систем уравнений полиномиального типа, часто решаемые с помощью базисов Гребнера,
возникают в различных теоретических и прикладных разделах математики, механики, криптографии и~т.~п.
Вопросы, которые можно ставить о таких системах, не обязательно требуют поиска всех ее решений; 
они могут быть связаны с размерностью пространства решений, с исключением из системы определенных неизвестных, 
с приведением системы к более удобному виду и~т.~д. 
Традиционный инструмент для конструктивного исследования таких систем~--- базис Гребнера~--- 
позволяет теоретически дать ответ на поставленные задачи, 
но его практическое вычисление обычно сопряжено с колоссальными  вычислительными затратами. 
Кроме традиционного алгоритма Бухбергера с различными оптимизациями~\cite{Buchberger, BW, GebauerMoeller, Cox} 
существуют также инволютивные алгоритмы~\cite{Gerdt}, 
алгоритмы, основанные на вычислении базиса модуля сизигий~\cite{Syzygies}, 
матричные алгоритмы~\cite{F4} и алгоритмы с исключением нулевых редукций~\cite{F5}. 
Большинство алгоритмов работают с S-полиномами~--- специальными многочленами, построенными по исходным образующим. 
Некоторые из этих алгоритмов имеют дополнительные ограничения на исходные многочлены, 
при которых возможна их эффективная работа. 
Основное время тратится на редукцию этих S-полиномов; 
если в результате получается ненулевой остаток, то он добавляется к промежуточному базису. 
Все эти алгоритмы являются последовательными. 
В научной литературе в 90-х гг. было распространено мнение, что алгоритмы построения базисов Гребнера в принципе плохо поддаются распараллеливанию~\cite{FaugereParallel, MityuninPankratiev}. 
На сегодняшний день известно сравнительно немного параллельных реализаций 
тех или иных алгоритмов~\cite{AttardiTraverso, GerdtParallel, Tran, Yanovich}.

В работе рассмотрены варианты распараллеливания алгоритма F4. 
Он относится к так называемым алгоритмам матричного типа и хорошо зарекомендовал себя на практике~\cite{F4, Roune}. 
Главное отличие матричных алгоритмов от традиционных методов заключается в том, что процесс редукции формулируется не в терминах многочленов, 
а переводится на линейно-алгебраический язык и сводится к задаче приведения большой разреженной матрицы к ступенчатому виду. 
Методы работы с разреженными матрицами изучены намного лучше и потому могут быть реализованы эффективнее. 
Другое отличие состоит в том, что на очередном шаге алгоритма рассматривается не один S-полином, 
а сразу некоторое подмножество S-полиномов. 
Критерии формирования этого подмножества могут давать различную эффективность в зависимости от задачи. 
Так, для однородных систем уравнений хорошим выбором является нормальная стратегия.
Распараллеливание алгоритмов матричного типа производилось в их линейно-алгебраической части, 
поскольку именно матричная редукция занимает в среднем 90\% времени работы последовательной версии алгоритма. 
Были разработаны специальные методы параллельного приведения сильно разреженной матрицы к ступенчатому виду. 
Для этого пришлось преодолеть ряд сложностей. Во-первых, столбцы таких матриц соответствуют мономам исходных многочленов. 
Они должны быть упорядочены согласно выбранному мономиальному порядку, поэтому элементарные преобразования столбцов матрицы запрещены. 
Из-за этого многие специальные параллельные матричные алгоритмы оказываются неприменимыми. 
Кроме того, несмотря на свою разреженность, матрицы, возникающие при вычислении базисов Гребнера, имеют особую структуру, 
полученную в результате специальной процедуры формирования матрицы~--- препроцессинга. 
Так, приведение случайной матрицы к ступенчатому виду с таким же коэффициентом разреженности может оказаться в среднем эффективней, 
чем приведение матрицы, реально появившейся в алгоритме. 
Все эти особенности были учтены при распараллеливании. 
В результате был создан настраиваемый параллельный блочный метод, 
в котором элементарные преобразования производятся не относительно отдельной строки, 
а сразу относительно специально выбранного блока. 
%При этом поддерживается авторедуцированный вид матрицы, что позволяет сразу выписывать в ответ те строки, 
%которые заведомо не будут далее редуцироваться. 
Особое внимание было уделено настройке стратегии выбора S-пар, 
стадии формирования матрицы и препроцессинга: 
они были переписаны таким образом, чтобы по возможности сохранить разреженность матрицы и уменьшить время вычислений. 
Отдельное исследование было посвящено алгоритмам работы с системами уравнений над полем из двух элементов, 
решение которых также ищется в этом поле (а не в его расширении). 
Такие системы часто встречаются, например, в криптографических задачах. 
Это эквивалентно исследованию системы с добавленными уравнениями поля $x_i^2=x_i$ для каждой переменной.
Тогда с учетом редукции можно считать, что все мономы обрабатываемых многочленов свободны от квадратов. 
Для различных последовательных и параллельных алгоритмов были 
реализованы специальные высокоэффективные методы для хранения и обработки таких многочленов.

Распараллеливание осуществлялось с использованием программного интерфейса MPI. 
Была создана специальная библиотека libF4mpi на языке программирования C++. 
Реализованные параллельные алгоритмы показали довольно неплохие результаты, 
что подтверждается экспериментальными вычислениями на многопроцессорных кластерах с распределенной памятью как для стандартных тестовых примеров, 
на которых традиционно проверяют работу систем компьютерной алгебры, так и на специфических прикладных и теоретических задачах. 


\section{Базисы Гребнера и алгоритм Бухбергера}

Мы будем рассматривать идеалы в кольце многочленов $F[x_1, \ldots, x_n]$, где $F$~--- конечное поле $F_p$ из $p$ элементов.
Мы называем мономом выражение $x_1^{a_1} \ldots x_n^{a_n}$, где $a_i \ge 0$, а термом~--- моном с коэффициентом (одночлен).
Через $\admOrdLe$ мы будем обозначать мономиальное упорядочение~--- линейный порядок на множестве мономов $\M$,
удовлетворяющий следующим свойствам для произвольных мономов $M$, $N$ и $Q$:
\begin{itemize}
 \item[--- ] $M \admOrd N \; \iff \; M \cdot Q \,\admOrd\, N \cdot Q$;
 \item[--- ] $M \admOrdGe 1$.
\end{itemize} 
Мы будем предполагать, что переменные упорядочены так, что  $x_1 \admOrdG x_2 \admOrdG \ldots \admOrdG x_n$.
Классические примеры мономиальных упорядочений~--- лексикографическое (Lex), степенное лексикографическое (DegLex)
и степенное обратное лексикографическое (DegRevLex).
Пусть $M=\prod\limits^n_{i=1}x^{a_i}_i$ и $N=\prod\limits^n_{i=1}x^{b_i}_i$. Тогда
\begin{itemize}
\item[--- ] $M\admOrd_{\rm Lex} N \; \Longleftrightarrow  \; 
 (a_1,\ldots, a_n) <_{\rm Lex} (b_1,\ldots, b_n)$,\\
 то есть, $a_1<b_1$, или $a_1=b_1$ и $a_2<b_2$, или $a_1=b_1, a_2=b_2$ и $a_3<b_3$ и~т.~д.;
\item[--- ] $M\admOrd_{\rm DegLex}N \; \Longleftrightarrow \; 
 (\sum_{i=1}^n a_i, \, a_1,\ldots, a_n) <_{\rm Lex} (\sum_{j=1}^n b_j, \,b_1,\ldots, b_n)$;
\item[--- ] $M\admOrd_{\rm DegRevLex} N \; \Longleftrightarrow \; 
 (\sum_{i=1}^n a_i, \, b_n, \ldots, b_1) <_{\rm Lex} (\sum_{j=1}^n b_j, \,a_n,\ldots, a_1)$.
\end{itemize}
Если зафиксировано мономиальное упорядочение, то можно вычислить старший моном $\HM(f)$, 
старший коэффициент $\HC(f)$ и старший терм $\HT(f)$ ненулевого многочлена $f$.
Более того, можно ввести понятие алгоритма редукции многочлена $f$ по множеству многочленов~$G$.
Редукция последовательно заменяет очередное подходящее слагаемое $c\cdot M$ многочлена $f$
на многочлен вида $c\cdot M - hg$, где $g \in G$, $h \in F[x_1, \ldots, x_n]$ и $\HT (hg) = c \cdot M$.
Результатом редукции может быть либо $0$, либо многочлен $f'$, старший моном которого не больше $\HM(f)$.
Мы будем записывать это так: $\Red{f}{G}{f'}$.


Существует несколько эквивалентных определений базиса Гребнера~\cite{BW, Cox, Pankratiev}. 
Приведем здесь два из них:

\begin{definition}
Множество $G\subset I$ называется базисом Гребнера идеала $I$, 
если идеал, порожденный старшими мономами $G$, совпадает с идеалом, порожденным старшими мономами~$I$.
\end{definition}

\begin{definition}
Множество $G\subset I$ называется базисом Гребнера идеала $I$, 
если любой $f\in I$ редуцируется к нулю относительно $G$ каким-либо фиксированным алгоритмом редукции.
\end{definition}

Базисы Гребнера в кольце многочленов от конечного числа переменных над полем 
используются для конструктивного описания идеалов и факторколец~\cite{BW, Cox, Pankratiev}.
В частности, с их помощью решается задача принадлежности произвольного многочлена рассматриваемому идеалу. 
Имеет место теорема Гильберта о базисе, утверждающая, что кольцо многочленов нетерово 
(то есть каждый идеал в нем имеет конечный набор образующих).
Именно этот факт позволяет алгоритмически вычислить базис Гребнера за конечное число шагов.
Имеется несколько алгоритмов вычисления базисов Гребнера. 
Каждый из них использует в той или иной мере следующий факт: 
существуют <<хорошие>> конечные подмножества идеала $I$, 
такие, что достаточно проверить редуцируемость к нулю элементов этих множеств относительно $G$ 
вместо того, чтобы проверять редуцируемость к нулю {\it каждого} элемента идеала. 
Классическим примером таких подмножеств является набор S-полиномов исходных образующих.

\begin{definition}
Пусть зафиксирован мономиальный порядок. 
S-многочленом (или S-полиномом) многочленов $f$ и $g$ называется многочлен
$$
\frac{\LCM(\HM (f), \HM (g))}{\HT (f)}f - \frac{\LCM(\HM (f), \HM (g))}{\HT (g)}g.
$$
\end{definition}

Смысл этого определения такой: многочлены $f$ и $g$ сначала домножаются минимальным образом на некоторые мономы так, 
чтобы у них оказался одинаковый старший моном (равный $\LCM$ исходных старших мономов). 
Затем из одного домноженного многочлена вычитается другой с таким подходящим коэффициентом, чтобы эти старшие мономы сократились.

Основное утверждение теории базисов Гребнера состоит в следующем~\cite{BW, Cox, Pankratiev}:
\begin{theorem}
Набор многочленов $f_1,f_2,\dots,f_n$ является базисом Гребнера идеала $(f_1,f_2,\dots,f_n)$, 
тогда и только тогда, когда для любой пары $(f_i,f_j)$ S-полином $S(f_i,f_j)$ редуцируется относительно этого набора к нулю.
\end{theorem}

Отсюда получается алгоритм Бухбергера: до тех пор, пока есть нерассмотренные пары многочленов, 
выбираем одну из них, строим для нее S-полином, редуцируем его по множеству текущих образующих идеала
и если получился не ноль, то добавляем результат к множеству образующих.
При каждом пополнении множества образующих увеличивается строго возрастающая цепочка идеалов их старших мономов.
Поэтому ввиду нетеровости кольца $F[x_1,\ldots,x_n]$ через конечное число шагов алгоритм закончит работу. 

Алгоритм Бухбергера является исторически первым алгоритмом построения базиса Гребнера. 
Описанная простая версия этого алгоритма является крайне неэффективной.
Другие алгоритмы построения базиса Гребнера тоже основаны на переборе S-полиномов и применении редукции.
Повышение эффективности алгоритмов достигается, как правило, за счет более грамотного перебора S-полиномов 
и за счет применения техники линейной алгебры.

Хорошо известны два критерия Бухбергера, которые гарантируют, что те или иные пары многочленов (критические пары) 
заведомо рассматривать не нужно, так как полученный S-полином будет редуцироваться к нулю по текущему множеству многочленов:
\begin{enumerate}
 \item если старшие мономы многочленов $f_i$ и $f_j$ взаимно просты, то $S(f_i,f_j)$ редуцируется к нулю по множеству $\{f_i,f_j\}$
  (первый критерий Бухбергера);
 \item если существует тройка многочленов $f_i,f_j,f_k$, такая, что $\HM(f_k) \, \mid \, \LCM(\HM(f_i),\HM(f_j))$ 
и пары $(f_i,f_k)$ и $(f_j,f_k)$ уже рассмотрены, то пару $(f_i,f_j)$ можно не рассматривать (второй критерий Бухбергера).
\end{enumerate}
Эти два критерия существенно уменьшают количество рассматриваемых критических пар и на порядки ускоряют алгоритм. 

Каждый нетривиальный идеал при фиксированном упорядочении обладает бесконечным множеством базисов Гребнера. 
Однако можно ввести понятие минимального и редуцированного базиса Гребнера. 
Редуцированный базис уже однозначно определяется идеалом и мономиальным упорядочением. 
Его можно получить из любого базиса Гребнера с помощью процесса авторедукции 
(замены слагаемых на эквивалентные им по модулю идеала выражения с меньшими мономами с помощью вычитания многочленов с подходящими старшими мономами) 
и последующей нормировкой старших коэффициентов.

Основным недостатком метода базисов Гребнера является высокая сложность вычислений. 
Поэтому важной задачей является создание быстрых и эффективных программных библиотек для построения базисов Гребнера. 
Повысить эффективность программ можно как за счет оптимизации самих алгоритмов, 
так и благодаря их распараллеливанию. Алгоритмы могут работать с разной эффективностью на различных входных данных, 
однако существует общепризнанный набор стандартных тестовых примеров\footnote{См., например, http:/\!/www.math.uic.edu/\textasciitilde{}jan/demo.html.} 
(как правило, возникших из конкретных прикладных задач), 
на которых традиционно проверяется скорость работы таких алгоритмов. 

В данной статье описывается параллельная реализация алгоритма F4 для вычисления базисов Гребнера 
в кольце многочленов над простым конечным полем с помощью матричных вычислений.



\section{Алгоритм F4}

Алгоритм F4 был предложен французским математиком Ж.-Ш.~Фожером в 1999 году~\cite{F4}. 
Основная идея алгоритма F4~--- заменить шаг редукции многочлена по множеству шагом редукции {\it множества} многочленов по множеству. 
Для этого вычисление очередных результатов редукций S-полиномов сводится к линейно-алгебраической задаче: 
приведению большой разреженной матрицы к ступенчатому виду. 
Строки этой матрицы соответствуют многочленам редуцируемого множества $X$ и того множества, 
по которому производится редукция $Y$ (они собираются вместе). 
Столбцы матрицы соответствуют мономам, которые встречаются в слагаемых многочленов из $X \cup Y$. 
Элементами матрицы являются коэффициенты соответствующих многочленов. 
Поскольку операции над строками данной матрицы соответствуют линейным комбинациям исходных многочленов с коэффициентами в основном поле 
(нельзя брать комбинации с полиномиальными коэффициентами), 
то для моделирования полиномиальной редукции приходится использовать так называемый {\it препроцессинг}. 
Эта операция состоит в добавлении к множеству $X\cup Y$ многочленов этого же множества, 
домноженных на подходящие мономы (если старший моном такого домноженного многочлена потенциально может быть использован при редукции). 
Эта процедура выполняется сравнительно быстро. 
Гораздо большее время занимает приведение матрицы к ступенчатому виду (по которому можно восстановить результаты редукции), 
так как размеры матрицы могут быть колоссально большими из-за добавления <<домноженных>> многочленов. 
В работе~\cite{F4} сообщается, что при вычислении базисов Гребнера некоторых идеалов размеры матрицы достигали $750000 \times 750000$. 
Поэтому эффективность алгоритма F4 во многом зависит от того, какими методами линейной алгебры матрица приводится к ступенчатому виду. 
Эти методы подробно рассматриваются ниже.

Алгоритм F4 предполагает некоторый произвол в выборе редуцируемого за один раз на каждом шаге множества S-полиномов. 
Так, если на каждом шаге выбирается один S-полином, то он повторяет классический алгоритм Бухбергера. 
Другая крайность~--- когда на очередном шаге редуцируется множество всех имеющихся S-полиномов. 
Это тоже не очень эффективно из-за больших размеров матриц. 
Автор алгоритма Ж.-Ш.~Фожер предложил {\it нормальную стратегию} выбора S-полиномов для редукции, 
согласно которой выбираются S-полиномы с наименьшей степенью левых и правых частей. 
Она дает хорошие эмпирические результаты для упорядочения ${\rm DegRevLex}$
и ее выбор является естественным для однородных идеалов.

В алгоритм можно внести несколько естественных усовершенствований. 
Как и в классическом алгоритме вычисления базиса Гребнера, можно применять критерии Бухбергера 
(метод Гебауэера--Меллера~\cite{BW,GebauerMoeller}) для отсеивания заведомо ненужных S-полиномов. 


\subsection*{Псевдокод алгоритма F4}
Алгоритм F4, строящий по множеству многочленов \texttt{givenPolynomials} его базис Гребнера \texttt{result}, имеет вид:

\begin{tabbing}
\qquad \=(basis\=, sPairs) $\leftarrow$ Update($\varnothing$, $\varnothing$, givenPolynomials)\\
\>{\bf while} sPairs $\neq\varnothing$ {\bf do}\\
\>\>selectedPairs $\leftarrow$ SelectPairs(sPairs)\\
\>\>sPairs $\leftarrow$ sPairs$\backslash$selectedPairs\\
\>\>newElements $\leftarrow$ Reduce(selectedPairs, basis)\\
\>\>(basis, sPairs) $\leftarrow$ Update(basis, sPairs, newElements)\\
\>{\bf end while}\\
\>result $\leftarrow$ Autoreduce(basis)\\
\end{tabbing}

Функция \texttt{Update: (basis, sPairs, newElements)}$\rightarrow$\texttt{(newBasis, newSPairs)} строит на основании текущего промежуточного базиса \texttt{basis}, множества нерассмотренных S-пар \texttt{sPairs} и множества \texttt{newElements} <<новых>> (не рассматривавшихся ранее) элементов идеала новый промежуточный базис \texttt{newBasis} и множество S-пар для рассмотрения (\texttt{newSPairs}) с учетом критериев Бухбергера.



\subsection*{Функция \texttt{Reduce}}

Наиболее трудоемкой частью алгоритма F4 с вычислительной точки зрения является процедура редукции набора S-пар \texttt{selectedSPairs}
по множеству многочленов \texttt{basis}. 
Про множество редукторов при этом дополнительно известно, что оно топ-авторедуцировано 
(то есть никакие два элемента множества старших мономов многочленов из \texttt{basis} не делятся друг на друга), 
и что S-пары порождены тем же множеством \texttt{basis}, по которому происходит редукция. 

Сформулируем спецификацию функции \texttt{Reduce} на алгебраическом языке.
Пусть $M = \texttt{selectedSPairs}$ (можно считать, что это набор левых и правых частей S-полиномов) и $B = \texttt{basis}$.
Положим $Q = \max_{f \in M} \HM f$.
Рассмотрим множество 
$$
 \Bar{B} = \{ m b \, \mid \, m \in \M, \; m \admOrdLe Q, \; b \in B \},
$$
представляющее собой базисные многочлены, домноженные на мономы.
Для каждого старшего монома элемента $\bar{B}$ выберем каким-либо способом
одного представителя из $\bar{B}$ с таким же старшим мономом и составим из этих представителей множество редукторов~$R$.
Таким образом, $\HM R = \HM \bar{B}$ и старшие мономы различных элементов $R$ не совпадают.
Далее в векторном пространстве $\langle M \cup R \rangle \subset F[x_1, \ldots, x_n]$ выберем базис
$\{g_i\}$ с условием, что все старшие мономы $\HM g_i$ различны.
Выделим подмножество базисных элементов
$$
 G = \{ g_i \, \mid \, \HM g_i \text{ не делится ни на какой моном из множества } \HM \left( B \cup \{g_j\}_{j \ne i} \right) \}.
$$
Это и есть новые многочлены, которые следует добавить на очередном шаге к промежуточному базису.

Итак, в алгоритме F4 в качестве редукторов используются только элементы заранее подготовленного 
множества $R=\{m b\}$, $b \in B$, все старшие мономы которого различны.  
После начала преобразований никакие элементы в него уже не добавляются. 
Этот подход и называется препроцессингом.
Он делает информацию о мультипликативных свойствах мономов ненужной в основном цикле преобразований. 
Перед началом преобразований можно перенумеровать все встречающиеся мономы по убыванию 
(чтобы старшим мономам соответствовали первые столбцы матрицы). 
После получения результата мультипликативные свойства вновь становятся нужны, поэтому перед выдачей ответа нужно провести 
обратную замену номеров на мономы. 
Выигрыш от замены мономов на номера состоит исключительно в повышении эффективности~--- 
как с точки зрения памяти, так и с точки зрения производительности.
В итоге задача свелась к редукции матрицы  $M$ (соответствующей S-парам) по матрице $R$ (соответствующей редукторам).
Благодаря тому, что по построению матрица $R$ уже имеет ступенчатый вид,
задача эквивалентна нахождению ступенчатого вида для объединенной матрицы, составленной из строк $M$ и $R$. 
Из полученного результата нужно выкинуть нулевые строки, а также строки, у которых старшие мономы совпадают со старшими мономами $R$. 
Заметим, что благодаря предварительному препроцессингу в окончательном результате вычислений не могут появиться строки, 
старший моном которых делится на какой-то старший моном редуктора из $R$, но не равен никакому старшему моному редуктора.





\subsection*{Возможности варьирования результата}
Вообще говоря, искомое множество $G$  не единственно. Это объясняется тем, что, хотя редуктор $mb$ с заданным старшим мономом единственен 
в течение всей редукции, он может быть изначально выбран разными способами. 
Рассмотрим пример, где $M$ состоит из единственного S-полинома, образованного двумя первыми многочленами из $B$ 
(порядок на мономах лексикографический, $a>b>c>d>e$):
$$
 B=\{a^2+1, \, ab+de, \, ad-b, \, ae-1\}, \; M=\{ade-b\}.
$$
В качестве редуктора можно взять как $e(ad-b)$, так и $d(ae-1)$. 
В первом случае получится $be-b$, во втором $-b+d$. 
В обоих случаях полученные многочлены не редуцируются дальше по $B$, 
и, следовательно, уже образуют результирующие множество $G$. 
Из этого примера видно, что набор старших мономов $G$  неоднозначен. 
Более того, если бы в $B$ был еще и многочлен $be-b$, то в первом случае произошла бы редукция до нуля, 
в то время как во втором редукции до $0$ не произошло бы. 
Таким образом, неоднозначно определено даже то, есть ли в $G$  ненулевые элементы.

Постановка задачи оставляет свободными 4 параметра:
\begin{itemize}
\item[--- ] способ формирования множества редуцируемых многочленов $M$ по набору S-пар;
\item[--- ] способ выбора множества редукторов $R$;
\item[--- ] порядок, в котором происходят разрешенные преобразования;
\item[--- ] проведение дополнительных преобразований (например, авторедукции).
\end{itemize}
Рассмотрим их подробнее.

\subsubsection*{Формирование множества редуцируемых многочленов $M$}
Рассмотрим два способа формирования набора строк матрицы $M$ из множества S-пар:
\begin{enumerate}
 \item добавление отдельно левых и правых частей S-пары;
 \item добавление отдельных S-полиномов (обозначим их множество через $M_0$). 
\end{enumerate}
Заметим, что в первом случае в матрице будет в два раза больше строк,
что может несколько увеличить объем вычислений при проведений редукций не по ведущему столбцу. 
Левые и правые части S-пары имеют такой же вид, как и редукторы (они представляют собой исходные базисные многочлены,
домноженные на мономы).
Поэтому в первом случае при препроцессинге их не следует учитывать.
Заметим также, что в отличие от второго способа, 
в первом случае операции сложения и вычитания достаточно реализовать только для строк матриц, но не для многочленов. 
Кроме того, в первом случае могут появиться дополнительные многочлены в результатирующем множестве $G$.

Эффективность этих способов зависит от количества S-пар с одинаковыми старшими мономами:
если их мало, то выгоднее пользоваться вторым методом, а если много~--- первым. 
Количество таких пар зависит от стратегии выбора подмножества S-пар на каждой итерации цикла F4 и от конкретной задачи.
На практике немного более эффективным оказывается второй способ.

В общем случае $M$ обязано обладать следующими двумя свойствами:
\begin{itemize}
 \item[--- ] все элементы $M_0$ выражаются через элементы $M$ с помощью линейных преобразований;
 \item[--- ] все многочлены из $M$ принадлежат идеалу, порожденному $B$.
\end{itemize}
Первое условие необходимо для того, чтобы $G$ содержало те многочлены (с точностью до линейных преобразований), 
которые появились бы, если бы вместо $M$ рассматривалось $M_0$. 
Второе~--- для того, чтобы  все полученные после редукции многочлены также принадлежали идеалу, порожденному $B$. 



\subsubsection*{Способ выбора множества редукторов $R$}
Можно использовать два подхода к выбору $R$. 
Первый подход~--- добавлять в $R$ новые элементы (если подходящие многочлены существуют) всякий раз, 
когда в нем не находится редуктора с заданным старшим мономом (то есть, добавлять редукторы по мере необходимости). 
Так работает классический алгоритм Бухбергера. 
Второй подход~--- заранее вычислять и помещать в $R$ множество всех многочленов, которые могут потенциально пригодиться при редукции,
то есть проводить препроцессинг. 
Этот подход применяется в классическом алгоритме F4. 
В обоих случаях, если в $R$ уже есть многочлен с рассматриваемым старшим мономом, то для редукции его и следует использовать.

Фиксирование множества редукторов $R$ позволяет практически полностью избавиться от неоднозначности. 
В самом деле, для фиксированных множеств $M$ и $R$ и количество многочленов, полученных в результате редукции, и их старшие мономы определены однозначно. 
В свою очередь, при фиксированном $R$ выбором $M$ можно пытаться получить в результате редукции некоторые дополнительные многочлены по сравнению с теми, 
что получились бы при взятии $M_0$. 
Поскольку над элементами множества $M$ разрешены линейные преобразования, 
то существенную роль с точки зрения возможного результата играет не само $M$, а лишь его линейная оболочка. 
Но на объем вычислений может влиять и конкретный выбранный набор векторов, порождающий  векторное пространство $\langle M \rangle$.

\subsubsection*{Порядок преобразований и авторедукция}
При заданных $M$ и $R$ на набор старших мономов результата уже ничего не влияет, и все преобразования имеют вид $a\leftarrow a+mb$, 
где $a$~--- многочлен из преобразуемого множества, $m$~--- элемент поля, а $b$ может быть как из преобразуемого множества $M$, так и из $R$. 
Хотя результат от порядка проведения этих преобразований существенно не зависит,  
последовательность выполнения операций может существенно влиять на объем вычислений
из-за большой разреженности. 
Единственное, что все еще неоднозначно определено в результате,~--- это мономы многочлена, следующие после ведущего (мономы <<хвоста>>). 
Могут существовать не старшие мономы, совпадающие с ведущими элементами какого-то другого многочлена. 
Они могут быть редуцированы (обнулен коэффициент) с помощью вычитания этого многочлена. 
Такое преобразование называется {\it авторедукцией}. 
В зависимости от порядка проводимых операций, часть авторедукций может быть уже неявно проведена (отсюда и возникает несущественная неоднозначность результата). 
Можно дополнительно применить авторедукции к множеству, 
которое уже удовлетворяет требованию на результат о неделимости старших мономов $G$ на старшие мономы $B$. 
Если провести все возможные авторедукции элементов $M$ по элементам $M$ и $R$ ({\it полную авторедукцию}), 
то результат будет удовлетворять усиленному требованию~--- теперь {\bf все} его мономы не будут делиться ни на старшие мономы $B$, 
ни на старшие мономы результата. 
Такой {\it авторедуцированный вид} будет строго единственен при фиксированных множествах $M$ и $R$. 
Смысл проведения авторедукций состоит в том, что, несмотря на увеличение объема вычислений на данном шаге, 
другой вид младших мономов результата может существенно снизить объем вычислений на последующих шагах F4.





\section{Идеи распараллеливания и реализация}
Непосредственно распараллеливание применяется к задаче нахождения ступенчатого вида одной матрицы, 
поскольку она занимает основную часть времени работы алгоритма. 
Сначала все строки матрицы равномерно делятся на блоки и рассылаются по разным процессорам.
Далее применяется блочный метод Гаусса, работа в котором идет в терминах блоков строк.
Операции редукции блоков, находящихся на разных процессорах, выполняются параллельно. 

Поскольку в исходных многочленах присутствовали далеко не все мономы, 
матрица $M \cup R$ обладает большой разреженностью: большинство ее элементов равно~$0$. 
На практике заполнение составляет примерно $0.3--3\%$, хотя в отдельных случаях оно падает до $0.1\%$ или даже увеличивается до $20\%$. 
Для эффективного использования такой большой разреженности требуется учитывать ее при хранении строк и в реализации метода Гаусса. 
Представление строк реализовано по аналогии с многочленами с заменой монома на номер столбца: 
строка является массивом, содержащим только ненулевые коэффициенты и соответствующие им номера столбцов. 
Элементы массива упорядочены по возрастанию номеров столбцов, так чтобы  элемент с наименьшим номером (ведущий) оказался в начале. 
В этом случае доступ к нему будет наиболее эффективен, что важно, поскольку ведущий элемент строк при работе алгоритма редукции 
просматривается чаще остальных.

Равномерность загрузки процессоров определяется двумя основными факторами: близким числом строк на разных процессорах 
(оно может меняться в процессе работы за счет обнуления некоторых строк, так как изначально матрица, как правило, вырождена) 
и равномерным распределением строк по процессорам с точки зрения номеров ведущих элементов (это особенность разреженного случая). 
Попытки применения эвристик для балансировки в процессе работы алгоритма показали, 
что подобные методы хотя и дают большую равномерность распределения, 
однако временные затраты на синхронизацию для выявления необходимой перебалансировки приводят лишь к увеличению общего времени.
Поэтому используется алгоритм, при котором все разделения строк на блоки и по процессорам рассчитываются единожды до начала редукции. 
Все последующие шаги проводятся строго в соответствии с этим разделением, 
а в процессе вычислений перебалансировки между процессорами не проводятся. 
Для того, чтобы при этом не происходило потери равномерности в процессе работы, применяется следующее распределение строк матрицы: 
множество всех строк матрицы, отсортированных по номеру столбца ведущего элемента, разделяется на равные по числу строк блоки. 
Эти блоки рассылаются по процессорам с циклическим перебором номера процессора-получателя, 
то есть процессор с номером $k$ (при $n$ процессорах всего) получает блоки, номера которых равны $k$ по модулю $n$. 
Разделение должно быть таким, чтобы в каждом блоке оказалось достаточно много строк 
(и была получена эффективность от блочных операций), а также, одновременно с этим, самих блоков должно быть достаточно много 
(чтобы время обработки одного шага на процессорах, содержащих на 1 блок больше, чем другие, отличалось незначительно и доля времени простоя, 
вызванного разным числом блоков на процессорах, была невелика). 
Именно этим объясняется то, что хорошие коэффициенты распараллеливания достигаются начиная с матриц, содержащих несколько тысяч строк.

После стадии рассылки все вычисления ведутся уже строго в терминах этих блоков~--- 
используется классическая блочная запись метода Гаусса с тем отличием, 
что разбиение на блоки зафиксировано изначально на стадии рассылки и не меняется в процессе работы~--- 
перераспределения строк не происходит не только между процессорами, но и между блоками на одном процессоре. 
В противном случае в пределах одного блока могли бы возникнуть строки с сильно различающимися ведущими столбцами, 
что привело бы к потере равномерности после редукции по нему. 
То есть, если какие-то строки блока обнулились в процессе редукции, то они выкидываются, 
а число строк в блоке уменьшается (вплоть до 0). Заимствования из других блоков того же процессора никогда не происходит. 
В остальном алгоритм соответствует блочно-параллельному методу Гаусса: 
на каждом шаге выполняются одновременно операции редукции блоков, находящихся на разных процессорах по одному и тому же 
заранее выбранному и переданному на все процессоры авторедуцированному блоку. 

Приведем в самом общем виде псевдокод реализованного блочно-параллельного алгоритма нахождения ступенчатого вида разреженной матрицы.
В алгоритме используются следующий переменные:
\begin{itemize}
\item[--- ] \texttt{Finished} --- множество уже отредуцированных строк.
\item[--- ] \texttt{Processing} --- множество блоков строк, находящихся в обработке.
\item[--- ] \texttt{Current\_block} --- блок строк, по которому производится редукция на данном шаге. Это множество совпадает на всех процессорах после вызова функции \texttt{send\_set\_to\_all\_from\_processor}.
\item[--- ] \texttt{Current\_processor} --- процессор, содержащий блок, по которому ведется редукция на данной итерации. Значение совпадает на всех процессорах, поскольку переменная одинаково меняется на каждой итерации цикла.
\end{itemize}

Также для взаимодействия используются следующие коммуникационные функции:
\begin{itemize}
\item[--- ] \texttt{this\_processor()} --- возвращает номер процессора на котором она вызвана (т.~е. <<этот>> процессор) в множестве всех процессоров, используемых в алгоритме (процессоры нумеруются последовательно, начиная с 0).
\item[--- ] \texttt{total\_processors()} --- суммарное число процессоров в системе.
\item[--- ] \texttt{is\_empty\_all\_processors(set)} --- булева синхронная функция, которая вызывается одновременно на всех процессорах. Ее возвращаемое значение также везде одинаково: оно равно истине тогда и только тогда, когда все множества, переданные ей в качестве аргумента, на всех процессорах пусты. Если хоть на одном процессоре \texttt{set} не пусто, то функция вернет ложь.
\item[--- ] \texttt{send\_set\_to\_all\_from\_processor(set, processor\_sender)} --- синхронная процедура, которая, будучи вызвана одновременно на всех процессорах с одинаковым аргументом \texttt{processor\_sender}, запишет в переменную \texttt{set} значение, содержащееся в этой переменной на \texttt{processor\_sender}. То есть, после вызова этой процедуры значение переменной \texttt{set} на всех процессорах будет одинаково.
\item[--- ] \texttt{unite\_all\_processors(set)} --- синхронная функция, возвращающая на каждом из процессоров множество, равное объединению аргументов \texttt{set} по всем процессорам.
\end{itemize}

Прочие процедуры, не являющиеся коммуникационными (выполняются на каждом из процессоров независимо):
\begin{itemize}
\item[--- ] \texttt{select\_row\_blocks\_for\_processor(matrix, processor)} --- возвращает подмножество блоков строк \texttt{matrix}, попадающих на \texttt{processor} при начальном разделении.
\item[--- ] \texttt{take\_row\_block(set\_of\_row\_blocks)} --- возвращает блок строк, содержащийся в \texttt{set\_of\_row\_blocks}, убирая его оттуда.
\item[--- ] \texttt{full\_reduce(matrix)} --- производит приведение матрицы к сильно ступенчатому виду (последовательная версия).
\item[--- ] \texttt{reduce\_matrix\_by\_matrix(matrix\_to\_reduce, reductor)} --- производит редукцию всех строк матрицы \texttt{matrix\_to\_reduce} по всем строкам \texttt{reductor} (последовательная версия, учитывающая разреженность).
\item[--- ] \texttt{add\_row\_block\_to\_set(block, set\_of\_row\_blocks)} --- добавляет блок строк к заданному множеству.
\end{itemize}

Следующий код параллельно исполняется на всех процессорах с одним и тем же аргументом \texttt{Matrix}.
Согласование поведения происходит за счет вызываемых коммуникационных процедур.
\texttt{
\begin{flushleft}
\textnormal{\textbf{\textsf{function}}} Reduce(Matrix) \{\\
\qquad Processing = select\_row\_blocks\_for\_processor (Matrix, this\_processor())\\
\qquad Finished = $\varnothing$\\
\qquad Current\_processor = 0\\
\qquad \textnormal{\textbf{\textsf{while not}}} is\_empty\_all\_processors(Processing) \{\\
\qquad\qquad  \textnormal{\textbf{\textsf{if}}} this\_processor() == Current\_processor \textnormal{\textbf{\textsf{then}}} \{\\
\qquad\qquad\qquad   Current\_block = take\_row\_block(Processing)\\
\qquad\qquad\qquad   full\_reduce(Current\_block)\\
\qquad\qquad  \}\\
\qquad\qquad  send\_set\_to\_all\_from\_processor(Current\_block, Current\_processor)\\
\qquad\qquad  reduce\_matrix\_by\_matrix(Processing, Current\_block)\\
\qquad\qquad  \textnormal{\textbf{\textsf{if}}} this\_processor() == Current\_processor \textnormal{\textbf{\textsf{then}}} \{\\
\qquad\qquad\qquad   add\_row\_block\_to\_set(Current\_block, Finished)\\
\qquad\qquad  \}\\
\qquad\qquad  Current\_processor = (Current\_processor + 1) \textnormal{\textbf{\textsf{mod}}} (total\_processors())\\
\qquad \}\\
\qquad \textnormal{\textbf{\textsf{return}}} unite\_all\_processors(Finished)\\
\}
\end{flushleft}
}

\bigskip

Авторами были созданы библиотеки программных средств F4mpi и F$_2$F4mpi (написаны на языке C++ с использованием интерфейса MPI). 
Данные библиотеки позволяют производить параллельные матричные вычисления базисов Гребнера при различных порядках на мономах 
над конечными полями и имеют дополнительные параметры настройки, такие как: 
указание стратегии выбора редуцирующих строк, 
явное задание размеров блоков при редукции матриц 
и набор параметров, отвечающих за настройку MPI-подсистемы.
Библиотеки были протестированы на многопроцессорных кластерах с распределенной памятью. 
В качестве тестовых примеров использовались стандартные системы из набора PoSSo и ряд систем, возникающих в прикладных задачах.
Среди этих задач~--- исследование систем уравнений, описывающих распределение нагрузки в электрических сетях; 
исследование уравнений из алгоритма шифрования с открытым ключом HFE; 
описание бифуркационной диаграммы интегрируемых гамильтоновых систем и~т.~д. 
Некоторые результаты тестирования приведены в таблицах.
В каждой ячейке указано общее время работы программы (в секундах), 
время приведения матриц к ступенчатому виду и общее ускорение относительно запуска на одном процессоре.


\bigskip
\begin{center}
\begin{tabular}{|l|c|c|c|c|}
\hline
Пример & 1 процессор & 2 процессора & 3 процессора & 4 процессора \\
\hline
Cyclic8 & 222/199 & 136/113 & 96/73 & 81/58 \\
(поле $F_{31013}$) & & 1.63 раз & 2.30 раз & 2.72 раз \\
\hline
Eco12 & 366/336 & 207/181 & 116/90 & 93/67 \\
(поле $F_2$) & & 1.76 раз & 3.14 раз & 3.92 раз \\
\hline
Hf855 & 117/106 & 63/53 & 31/20 & 27/16 \\
(поле $F_{31013}$)& & 1.83 раз & 3.74 раз & 4.26 раз \\
\hline
Noon8 & 2185/2071 & 1369/1296 & 649/587 & 387/325 \\
(поле $F_{31013}$) && 1.60 раз & 3.36 раз & 5.64 раз \\
\hline
\end{tabular}

\bigskip

\begin{tabular}{|l|c|c|c|c|c|}
\hline
Пример & 1  & 12  & 16  & 24 & 48\\
&процессор & процессоров & процессоров & процессора & процессоров \\
\hline
Eco12 & 1350/1249 & 208/147 & 175/116 & 154/96 & 137/80\\
(поле $F_{31013}$) & & 6.48 раз & 7.71 раз & 8.72 раз & 9.83 раз\\
\hline
Katsura10 & 516/492 & 92/67 & 79/55 & 72/48 & 69/45\\
(поле $F_{31013}$) & & 5.59 раз & 6.46 раз & 7.07 раз & 7.42 раз \\
\hline
Noon8 & 3299/3247 & 357/306 & 255/204 & 204/152 & 153/101\\
(поле $F_{31013}$)& & 9.22 раз & 12.90 раз & 16.13 раз & 21.44 раз\\
\hline
\end{tabular}
\end{center}


\bigskip

\section{Теоретический анализ эффективности авторедукции}

Строки, добавленные в матрицу $R$ в результате препроцессинга, в свою очередь можно разделить на 2 группы: 
\begin{itemize}
 \item[$A$:] строки, у которых старший моном встречается среди мономов матрицы $M$ (полученной из S-пар);
 \item[$B$:] строки, старший моном которых встречается в $R$, но не в $M$. 
\end{itemize}
Отличия между этими группами проявляются при проведении авторедукции строк $R$.

Для оценки эффективности временных затрат на авторедукцию положим, что прибавление к строке длины $m$ строки длины $n$ занимает $r(m, n)$ операций. 
Для простейшей реализации склеиванием двух упорядоченных массивов $r(m, n) = O (m + n)$. 
Также для большинства реализаций (тех, где можно разбить строку на $2$ отдельные части за константное число действий) 
будет выполнено соотношение $r (m, n_1 + n_2) \le r (m, n_1) + r (m, n_2)$, потому что длинную строку можно прибавлять по частям.  
Предположим также монотонность по обоим аргументам: при $N \ge n$, $M \ge m$ будет выполнено $r (m, N) \ge r (m, n)$ и $r (M, n) \ge r (m, n)$
(вообще, можно считать функцию $r$ симметричной). 
Эти соотношения будут использоваться ниже при оценке времени работы при различном порядке операций. 
За $\len (x)$ обозначим число ненулевых элементов в строке $x$.

Рассмотрим редукцию $\Red{x}{b}{y}$ строки $x$ с ненулевым элементом в столбце $c$ по строке $b \in B$ с ведущим элементом в столбце $c$ 
до строки $y$. Тогда по построению матрицы $R$ ведущие элементы у строк $x$ и $y$ совпадают. 
Пусть $U \subset M$~--- некоторый набор строк из верхней части матрицы, которые нужно отредуцировать по $x$ (и по $y$).
Заметим, что при редукции $\Red{u}{y}{u'}$, где $u \in U$, в столбце $c$ появляется ненулевой элемент, 
а при редукции $\Red{u}{x}{u'}$~--- не появляется.
Число операций при редукции всех строк из $U$ по $x$ и $b$ при проведении предварительной редукции $\Red{x}{b}{y}$ равно
$$
 C_1 = r(\len(x), \len(b)) + \sum_{u \in U} r(\len(u), \len(y)).
$$
Без проведения предварительной редукции $\Red{x}{b}{y}$ получаем следующий результат:
$$
 C_2 = \sum_{u \in U} (r(\len(u), \len(x)) + r(\len(u'), \len(b))),
$$
где $\Red{u}{x}{u'}$. Сравним эти выражения.
Одиночным слагаемым $r(\len(x), \len(b))$ можно пренебречь. 
Для оставшихся слагаемых при условии $\len( u') \ge \len(u)$ будет выполнена следующая цепочка неравенств:
\begin{gather*}
 {r(\len(u), \len(x))+r(\len(u'), \len(b))\ge r(\len(u), \len(x))+r(\len(u), \len(b)) \ge} \\
 \ge r(\len(u), \len(x)+\len(b))\ge r(\len(u), \len(y)).
\end{gather*}
Условие на длины $u'$ и $u$ будет выполнено практически во всех случаях из-за разреженности матрицы:
при добавлении $x$ к $u$ вероятнее добавление новых ненулевых элементов, нежели сокращение старых. 
Также соотношение $\len(x)+\len(b) \ge \len(y)$ будет всегда выполнено, поскольку в $y$, 
являющимся линейной комбинацией $x$ и $b$, не может быть больше ненулевых элементов, чем в $x$ и $b$ вместе взятых. 
Таким образом, от редукции строки $x$ по строке $b \in B$ всегда имеется положительный эффект с точки зрения производительности.

Рассмотрим теперь другой случай, когда вместо строки $b \in B$ используется строка $a \in A$ с ведущим элементом в столбце~$c$.
Пусть $\Red{x}{a}{y}$. Снова по построению множества $R$ получаем, что $c$ не является ведущим столбцом строки $x$.
Покажем, что если большое количество строк $u \in U$ содержат в столбце $c$ ненулевой элемент, 
то предварительная редукция $\Red{x}{a}{y}$ может привести к увеличению объема вычислений. 
Здесь, в отличие от предыдущей ситуации, после редукции вида $\Red{u}{x}{u'}$ в столбце $c$ могут по-прежнему остаться ненулевые элементы. 
Это произойдет независимо от того, была ли строка $x$ редуцирована по $a$ или нет, так как изначально значение, 
содержащееся в столбце $c$ строки $u$, в некотором смысле <<случайно>>, и вероятность его обнулить, редуцировав по $x$, мала. 
То есть, такую строку $u$ придется в любом случае редуцировать вначале по $x$ (или $y$), а потом по $a$.
Конечный результат редукции не будет зависеть от того, была ли проведена авторедукция $x$ до $y$. 
Для оценки зависимости объема вычислений в случаях проведения и непроведения предварительной редукции $x$ до $y$ 
от числа ненулевых элементов матрицы $M$ в столбце $c$ выпишем приближенное число операций для обоих случаев. 
Пусть $\Red{u}{x}{u'}$ и $\Red{u}{y}{u''}$.
Оценка на число действий при проведении предварительной редукции $\Red{x}{a}{y}$ такова:
$$
 E_1 = r(\len(x), \len(a))+\sum_{u\in K_1}(r(\len(u), \len(y))+r(\len(u''),\len(a)))+\sum_{K_2}r(\len(u), \len(y)).
$$
Без проведения редукции получаем
$$
 E_2 = \sum_{u\in{L_1}}(r(\len(u), \len(x))+r(\len(u'), \len(a)))+\sum_{u\in L_2}r(\len(u),\len(x)).
$$
Здесь
 \begin{itemize} 
  \item[]$K_1$~--- множество строк $M$ с ненулевым элементом в столбце $c$, которые редуцируются по $x$; 
  \item[]$K_2$~--- множество строк $M$, которые редуцируются по $x$, но содержат $0$ в столбце $c$; 
  \item[]$L_1$~--- множество строк $M$, которые после редукции по $x$ содержат ненулевой элемент в столбце~$c$;
  \item[]$L_2$~--- множество строк $M$, которые после редукции по $x$ содержат $0$ в столбце $c$.
 \end{itemize} 
Для них выполнены следующие соотношения:
\begin{gather*}
 K_1\cup K_2 = L_1\cup L_2=U,\\ %\{\text{все строки, редуцирующиеся по } x\},\\
 K_1\cap K_2=L_1\cap L_2=\varnothing,\\
 L_1\supset K_2 \text{ и } L_2 \subset K_1.
\end{gather*}
%(поскольку редукция по $x$ гарантированно приведет к появлению в столбце $c$ ненулевого элемента).
При вычислении над полями вычетов с большой характеристикой множество $L_2$ будет практически пусто, 
поскольку <<случайное>> появление нуля маловероятно. 
Однако при вычислениях по модулю $2$ проявляется противоположный эффект: $L_1 = K_2$, $L_2 = K_1$,
потому что в этом случае редукция по $x$ всегда заменяет значение в столбце $c$ на противоположное. 
При большом числе строк в множестве $U = K_1\cup K_2$ первым слагаемым, отвечающим за редукцию $\Red{x}{a}{y}$, можно пренебречь. 
Далее, $\len (y)$  превосходит $\len (x)$, поэтому для $i=1,2$ затраты на один элемент $K_i$ больше, чем на элемент $L_i$. 
Но поскольку в обоих случаях затраты для элемента первого множества превышают затраты для второго, 
решающую роль оказывает распределение элементов по множествам. 
Рассмотрим наиболее простой случай $r (a, b) = a + b$ и предположим, что разреженность достаточно велика для того, 
чтобы у любых двух строк было пренебрежимо мало общих ненулевых столбцов. 
Тогда можно положить
\begin{gather*}
 \len (y) = \len (x) + \len (a),\\
 \len (u') = \len (u) + \len (x),\\
 \len (u'') = \len (u) + \len (x) + \len (a).
\end{gather*}
Затраты при проведении предварительной редукции $\Red{x}{a}{y}$ будут равны
$$
 E_1 = \sum_{u\in K_1} (2\len(u)+3\len(a)+2\len(x)) + \sum_{u\in K_2}(\len(u)+\len(a)+\len(x)).
$$
Без проведения предварительной редукции получаем такую оценку на затраты:
$$
 E_2 = \sum_{u\in L_1}(2\len(u)+\len(a)+2\len(x))+\sum_{u\in L_2}(\len(u)+\len(x)).
$$
Их разность, с учетом того, что $L_1 \supset K_2$ и $L_2 \subset K_1$, дает
$$
 E_1 - E_2 = \sum_{u\in K_2}(-\len(u)-\len(x))+\sum_{u\in L_1\cap K_1} 2\len(a)+\sum_{u\in L_2}(\len(u)+3\len(a)+\len(x)).
$$
В случае большой характеристики поля последним слагаемым можно пренебречь (так как $L_2$ почти пусто), 
и редукцию $\Red{x}{a}{y}$ стоит проводить только если число элементов $K_2$ <<заметно>> на фоне $K_1$. 
Если же $K_2$ значительно меньше $K_1$, то разность будет положительна, и редукцию проводить не следует. 
В случае характеристики $2$ обнуляется второе слагаемое разности. 
Условие получается по сути то же самое~--- проводить редукцию только если $K_2$ больше $K_1$ ($=L_2$ в случае модуля $2$), 
но здесь $K_1$ входит с большим весовым коэффициентом, чем в предыдущем случае. 
В обоих случаях конкретные числовые коэффициенты на основе которых следует принимать решение о необходимости редукции $x$ по $a$ 
нужно выбирать в зависимости от средней длины $u$, $\len (a)$, $\len (x)$ и мощности $K_2$.

Для строк из $K_2$ было бы эффективней использовать редуцированную строку $x$ в любом случае. 
Но для реализации подобного метода, где часть строк редуцируются непосредственно $x$, а некоторые~--- строками, полученными из $x$, 
придется хранить и вычислять для каждой исходной строки $x$ много вариантов $y$  (результатов частичной редукции по различным поднаборам строк $A$). 
Их построение и выбор нужного варианта займет существенно больше времени, чем будет выиграно за счет чуть более эффективного проведения авторедукций.
Из этого следует, что для принятия точного решения о проведении авторедукции нужно заключение о том, окажется ли множество $K_2$ больше $K_1$.
Подобное заключение можно дать лишь при некотором дополнительном предположении о структуре матриц, например, 
оно выполнено при равномерном распределении ненулевых элементов для матриц с малой заполненностью 
(потому что строк у которых будут одновременно ненулевые элементы как в ведущем столбце строки $x$, так и в столбце $c$, окажется немного). 
В общем же случае ничего подобного утверждать нельзя, 
и вопрос эффективности проведения авторедукции матрицы существенно зависит от каждой конкретной матрицы. 
На практике несколько более эффективным обычно оказывается проведение предварительной авторедукции.















\section{Специфика вычисления базисов Гребнера над полем $F_2$}

Работа с многочленами с коэффициентами из поля $F_2$ имеет свои особенности, связанные со структурами данных.
Имеется несколько независимых исследований, учитывающих эти особенности (система PolyBoRi\footnote{http:/\!/polybori.sourceforge.net.}
(Polynomial over Boolean Rings), а также работа~\cite{GerdtZinin}).

Во-первых, это отсутствие коэффициентов при мономах в многочленах. 
Благодаря этому можно существенно оптимизировать хранение многочленов и операции над ними. 
Один из подходов заключается в так называемой плотной записи многочленов. 
Он заключается в следующем: занумеруем каким-нибудь способом все возможные мономы, которые можно составить из наших переменных. 
Желательно, чтобы нумерация была согласована с порядком на мономах, который мы используем, 
то есть если $p \admOrd q$, где $p$ и $q$~--- мономы, то $\Num(p) < \Num(q)$, где $\Num$~--- функция, 
сопоставляющая моному натуральное число. 
Также желательно, чтобы функция $\Num$ была <<непрерывной>>\footnote{Это возможно сделать
только при градуированных порядках (например, ${\rm DegRevLex}$) или если есть оценка на максимально 
возможную степень вхождения переменной в моном}, то есть, если 
$\exists \, p: \Num(p) = k - 1$ и $\exists \, q: \Num(q) = k + 1$, то $\exists \, r: \Num(r) = k$. 
Тогда будем хранить многочлен, как битовую маску, то есть как набор битов, причем в $k$-м по счету бите стоит $1$, 
если моном, которому соответствует число $k$ присутствует в многочлене и $0$, если он там отсутствует. 
При таком подходе в одной обычной переменной целого типа $\verb|int|$ можно будет хранить сразу $32$ ячейки, 
определяющие, есть ли соответствующий моном в многочлене. 
Взяв достаточное количество таких переменных и считая, что они расположены <<подряд>>, 
можно хранить полностью всю информацию о многочлене. 
При этом сложение многочленов соответствует побитовой операции \verb|xor|. 
Если в качестве функции, сопоставляющей мономам числа, взять функцию, возвращающую число, 
$r$-ичная запись которого представляет собой последовательность степеней вхождения всех имеющихся переменных в моном
(где $r$~--- максимально возможная степень вхождения переменной в моном, которую нужно оценить заранее), 
то умножение монома на моном будет соответствовать сложению значений функции, и, соответственно, 
умножение многочлена на моном будет соответствовать сдвигу всех цифр на одно и то же количество позиций, 
что также выполняется простым алгоритмом (такая нумерация соответствует порядку ${\rm Lex}$). 
При таком способе мы получаем плотную запись многочлена, то есть храним информацию и о тех мономах, 
которые в нем не содержатся, однако при этом тратим в $32$ раза меньше памяти и вычислительных операций. 
При таком способе хранения в алгоритме F4 вообще не нужно переводить многочлены в матрицу, а потом наоборот.
Итак, в случае, если плотность матрицы больше, чем $\frac{1}{32}$, то мы получаем здесь выигрыш.

Больший выигрыш дает другая идея. 
Обычно, находя базис Гребнера над конечным полем, мы предполагаем, что переменные, входящие в многочлены, 
принадлежат основному полю, а это означает, что они удовлетворяют уравнению поля $x^p - x = 0$, где $p$~--- характеристика. 
Для поля $F_2$ это сводится к уравнениям вида $x^2 - x = 0$. 
В этом случае следует искать базис Гребнера не для исходного набора многочленов, а для набора, 
к которому добавлены уравнения поля, записанные для каждой из переменных. 
Оказывается, что в этом случае можно сильно упростить действия над многочленами и мономами, 
фактически предполагая в них изначально уравнения поля, и при этом корректно получать базис Гребнера для набора многочленов, 
используя немного видоизмененные алгоритмы Бухбергера или F4.

Итак, перейдем сразу к кольцу многочленов, отфакторизованному по идеалу $(x_1^2 - x_1, x_2^2 - x_2, \dots, x_d^2 - x_d)$. 
В этом кольце останутся только мономы, у которых каждая переменная входит либо в степени $0$, либо в степени $1$. 
Каждому такому моному легко поставить в соответствие число, 
двоичная запись которого состоит из показателей степеней вхождения каждой из имеющихся переменных в моном. 
То есть, если всего у нас имеется $d$ переменных, то в двоичной записи числа, соответствующего каждому моному, 
будет содержаться ровно $d$ цифр, возможно, при этом в записи будут содержаться лидирующие нули. 
В этом случае умножение мономов будет соответствовать операции \verb|xor| над соответствующими им числами. 
Для исполнения алгоритма нам нужны следующие операции над мономами: 

\begin{enumerate} 
 \item Создание монома по набору переменных. 
  Для того, чтобы добавить в моном $k$-ю переменную, необходимо вычислить $[\frac{k}{32}]$~--- индекс элемента вектора, 
  в котором находится эта переменная. Далее нужно выполнить операцию \verb|xor| элемента вектора с числом $2^{k\,(\Mod\,32)}$.
  Эти операции реализованы как \verb|(k >> 5)| и \verb|(1 << (k & 31))| соответственно.
 \item Копирование мономов: $a = b$.
 \item Умножение мономов:
\begin{verbatim}
c[k] = a[k] | b[k]
\end{verbatim}
 \item Наименьшее общее кратное совпадает с произведением.
 \item Определение делимости одного монома на другой:
\begin{verbatim}
(a[k] & b[k]) == b[k]
\end{verbatim}
 для каждого индекса k векторов.
 \item Деление монома на моном (после проверки делимости):
\begin{verbatim}
c[k] = a[k] ^ b[k]
\end{verbatim}
 \item Вычисление степени монома соответствует вычислению размера битового множества. 
  Этот размер равен сумме количества единичных битов в каждом из элементов вектора. 
  В целях оптимизации для этой операции хранится специальная таблица из $65536$ элементов, 
  содержащая количество битов для каждого числа от $0$ до $2^{16} - 1$. 
  Тогда вычисление количества битов в \verb|unsigned int| выполняется с помощью двух обращений к таблице (для старшего и младшего байтов числа)
  и одного сложения.
\end{enumerate}

Теперь опишем способ хранения полиномов.
Будем считать, что порядок на мономах~--- это ${\rm DegRevLex}$. 
Описываемый способ можно видоизменить и для использования других порядков. 
Так как в первую очередь мономы упорядочиваются по степени, то предлагается хранить многочлен в виде набора ячеек, 
в каждой из которых будут храниться мономы одной и той же степени. 
Таким образом, всего нам может понадобиться не более $d + 1$ ячейки для одного многочлена. 
Внутри ячеек мономы будем хранить в виде упорядоченного множества, 
в котором сравнение производится уже просто по порядку ${\rm RevLex}$, так как степени мономов равны. 
Для многочленов нам нужно уметь выполнять две базовые операции:
\begin{enumerate}
 \item Умножение многочлена на моном. 
  Для этого нужно просто пройтись по всем ячейкам, в каждой ячейке по всем мономам, домножить каждый из них на наш множитель, 
  а затем положить в соответствующую ячейку результата, если там еще нет такого монома, 
  либо наоборот удалить из нее моном, если он там уже есть, так как два одинаковых монома сокращаются. 
  Номер ячейки определяется степенью монома, которую мы умеем вычислять.
 \item Сложение двух многочленов.  
  Для этого нужно уметь отдельно складывать их однородные части, лежащие в соответствующих друг другу ячейках. 
  Ячейки представляют собой упорядоченные множества, которые мы можем обходить по возрастанию. 
  Тогда сложение однородных частей сводится к нахождению симметрической разности между такими множествами, 
  что можно сделать за один проход по этим множествам в силу их упорядоченности.
\end{enumerate}

Заметим, что умножение на моном уже не сохраняет порядок мономов. 
Например, многочлен $x_1 x_2 + x_3$ после умножения на $x_1 x_2$ превращается в $x_1 x_2 x_3 + x_1 x_2$, и мономы меняются местами. 
Вследствие этого изменяется сам ход алгоритма, независимо от того, базовый используемый алгоритм~--- это F4, 
алгоритм Бухбергера или другой алгоритм вычисления базисов Гребнера.

Для того, чтобы действия в отфакторизованном кольце приводили к правильному ответу,
следует в начале выполнения алгоритма добавить к множеству ${f_1,f_2,\dots,f_n}$ 
все их кратные $x_if_j$, такие, что $x_i$ входит в $\HM(f_j)$. 
Эти многочлены являются S-полиномами пар $(f_j,x_i^2-x_i)$, 
редуцированными относительно $\{x_i^2-x_i\}_{i=1}^n$. 
Рассмотрим для доказательства два случая: когда старший моном $f_j$ делится на $x_i$ и когда не делится. 
Пусть $m$ - старший моном $f_j$. Если $m$ делится на $x_i$, то можно считать, что $x_i$ входит в $f_j$ в первой степени, 
так как иначе можно $f_j$ редуцировать по $x_i^2-x_i$. 
Тогда $S(f_j,x_i^2-x_i)=x_if_j-\frac{m}{x_i}(x_i^2-x_i) \rightarrow x_if_j$. 
Иначе $S(f_j,x_i^2-x_i)=x_if_j-m(x_i^2-x_i) \rightarrow x_if_j$. 
Соответственно, эти элементы добавить нужно. 
Далее, критерии Бухбергера применимы к новым многочленам. 
У каждого из многочленов в редуцируемом кольце есть прообраз в обычном кольце многочленов, однозначно определенный, 
так как все многочлены строятся, как S-полиномы из уже имеющихся, а затем редуцируются по множеству многочленов вида $x_i^2-x_i$. 
И хотя в нашем редуцированном кольце при домножении многочлена на моном порядок мономов в нем может измениться, 
а доказательства критериев используют свойства правильного порядка на мономах, 
откидываемые за счет критериев пары все равно нужно откидывать. 
Действительно, операция умножения на моном в нашем кольце просто соответствует умножению на тот же моном в обычном кольце многочленов, 
а затем редукции. После редукции старшие мономы многочлена в обычном кольце многочленов и в нашем редуцированном совпадут по определению. 
Следовательно, если мы можем применять критерии Бухбергера к старшим мономам многочленов в обычном кольце многочленов, 
то можем применять их и для отбрасывания пар в редуцированном кольце, 
так как полученные S-полиномы будут редуцироваться в обычном кольце многочленов к нулю относительно имеющегося множества, 
а мы ищем именно базис Гребнера для исходного кольца многочленов.

Добавлять такие домноженные многочлены нужно только в начале алгоритма.
Действительно, если на каком-то шаге мы получили многочлен $f$, то $f = \sum\limits_{i=1}^{n} p_if_i$, 
где $p_i$~--- некоторые многочлены, а $f_i$~--- исходный набор образующих. 
Тогда $x_i f = \sum\limits_{i=1}^{n} x_ip_if_i = \sum\limits_{i=1}^{n} p_i(x_if_i)$, 
а многочлены $x_if_i$ уже были добавлены на первом шаге.
Итак, если многочлен $f$ дает вклад в ответ, 
то он все равно будет получен другим путем, так как $x_ix_if_i=x_if_i$.

С другой стороны, изменения порядка мономов при домножении многочлена на моном несколько осложняет операции с многочленами. 
Было рассмотрено несколько вариантов хранения многочленов в зависимости от заданного упорядочения на мономах. 
Для степенных упорядочений, таких как ${\rm DegLex}$ и ${\rm DegRevLex}$, 
был рассмотрен вариант хранения мономов многочлена в виде \verb|vector <set <CMonomial> >|, где \verb|CMonomial|~--- класс монома. 
При этом в $i$-й ячейке вектора хранится множество всех мономов степени $i$. 
Тогда сложение многочленов сводится к сложению покомпонентно, а в каждой компоненте можно параллельно пройти по двум множествам 
в порядке обхода по возрастанию и таким образом создать новое множество, являющееся их симметрической разностью. 
В этом случае легко выполнить операцию извлечения старшего монома~--- нужно взять наибольший элемент множества, 
соответствующего старшей по степени компоненте многочлена. 
При этом мономы внутри одной компоненты уже не нужно сравнивать по степени, достаточно сравнивать их по порядку ${\rm Lex}$ or ${\rm RevLex}$.

Второй подход состоял в том, чтобы хранить все мономы в одном множестве \verb|set <CMonomial>|. 
Реализация в этом случае похожа на первый случай, однако отличается тем, что мономы внутри множества уже нужно сравнивать вначале по степени, 
зато не нужно вычислять степень мономов при сложении и умножении. 

Наконец, третий подход состоял в том, чтобы хранить все мономы просто в  векторе \verb|vector <CMonomial>|, 
упорядоченность которого следует поддерживать после выполнения каждой операции. 
Здесь нет накладных расходов, который есть у \verb|set <CMonomial>| при хранении, 
но зато при добавлении монома к многочлену уже нужно пройти через весь список мономов, чтобы найти место для вставки. 
Были реализованы все три варианта. На тестовых примерах лучше себя показал последний вариант, 
однако это, по всей видимости, связано с тем, что примеры относительно небольшие, 
и количество мономов в многочлене в них невелико. 
При увеличении размера задачи один из первых двух подходов может дать преимущество.

\subsection*{Дополнительные методы оптимизации}

Рассмотрим дополнительные методы ускорения программы в случае добавленных уравнений поля.
В алгоритме Бухбергера основное время уходит на явную редукцию S-полинома. 
Если делается только top-редукция, то есть, редукция лишь старших слагаемых, то иногда можно ускорить выбор подходящего редуктора. 
Различных мономов в алгоритме встречается не так много, и старшие мономы редуцируемых многочленов часто будут повторяться.
И если уже однажды был получен какой-то редуктор для такого старшего монома, 
то можно запомнить его и использовать при последующих вызовах функции. 
Для этого нужно в ассоциативном массиве хранить отображение из мономов в многочлены, сопоставляющее моному редуктор. 
Добавлять и искать элементы в нем можно за логарифмическое время от его размера. 
Получив очередной старший моном, мы сначала определим, не найден ли уже для него редуктор заранее, 
а в случае неудачи будем просматривать список всех редукторов 
как обычно\footnote{Заметим, что для вычислении инволютивных базисов Жане имеется специальная структура данных~--- дерево Жане,
позволяющая быстро найти подходящий делитель~\cite{JanetTree}.}.

Также для ускорения одной из самых частых операций~--- выбора старшего монома у многочлена~--- предпринято несколько шагов. 
Во-первых, в многочлене всегда хранится ровно столько ячеек, сколько необходимо, 
то есть в последней ячейке обязательно есть хотя бы один моном. 
Для поддержания этого при сложении многочленов и умножении их на мономы нужно в конце удалять пустые компоненты, 
однако это избавляет от необходимости каждый раз проходить по всему многочлену, чтобы найти последнюю ячейку, 
в которой хранится хотя бы один моном, а именно в ней и хранится старший моном многочлена в силу порядка, заданного на мономах. 
Сами же ячейки хранятся в виде упорядоченных множеств, благодаря чему мы можем найти наибольший элемент 
за логарифмическое количество операций от размера ячейки.

В алгоритме F4 есть несколько мест, в которых четко не указано оптимальной стратегии действия, 
так как оптимальная стратегия для выполнения соответствующих шагов неизвестна. 
Одно из таких мест~--- стратегия выбора набора критических пар, по которым будут строиться S-полиномы, 
рассматриваемые на очередном шаге. 
Если не рассматривать дополнительных параметров, то имеется несколько разных стратегий: 
\begin{enumerate}
 \item выбирать одну какую-нибудь пару~--- получаем обычный алгоритм Бухбергера;
 \item выбирать сразу все критические пары;
 \item выбирать все критические пары наименьшей степени (нормальная стратегия);
 \item выбирать все критические пары наименьшей степени после гомогенизации (сахарная стратегия).
\end{enumerate}
Фожер рекомендует третью стратегию: для однородных идеалов она является естественным выбором. 
Однако при реализации было выяснено, что в случае вычисления базисов Гребнера для серий cyclic 
с добавлением уравнений поля вторая стратегия дает выигрыш в два с небольшим раза. 
Теоретическая зависимость эффективости вычислений определенных серий примеров от конкретных стратегий пока мало изучена.

Далее, на самом деле, стратегия выбора критических пар на каждый шаг важна и в обычном алгоритме Бухбергера, 
если к нему применять оптимизации, связанные со вторым критерием Бухбергера. 
Дело в том, что критическая пара, добавленная в множество критических пар для рассмотрения, 
может так и не оказаться рассмотренной из-за какой-то будущей критической пары, 
вместе с которой они образуют бухбергеровскую тройку. 
Поэтому выбирать для рассмотрения все имеющиеся на данный момент критические пары на каждом шагу~--- это не то же самое, 
что выбирать их по одной по порядку. 
Оказалось, что и в обычном алгоритме Бухбергера именно стратегия выбора сразу всех имеющихся критических пар 
дает для случая с автоматическим добавлением уравнений поля выигрыш, причем, что удивительно, 
самый большой выигрыш из всех применявшихся оптимизаций. 
После смены стратегии с выбора одной пары на выбор сразу всех алгоритм ускорился даже не в константу раз, а на порядок.

\subsection*{Результаты работы и временные показатели}
Были реализованы два алгоритма~--- базовый алгоритм Бухбергера, снабженный всеми описанными оптимизациями, 
и алгоритм F4, снабженный теми из оптимизаций, которые к нему применимы. 
Программы называются PackedBuhberger и PackedF4, написаны на C++. 
Они запускались на трех стандартных сериях примеров~--- cyclic, eco и katsura. 
Выполнялись на компьютере Intel(R) Celeron(R) 2.4 GHz, 1Gb RAM. 
Сравнение проводилось с пакетом FGb 1.34 для системы компьютерной алгебры Maple. 
FGb также реализован на С.
Ниже приведены таблицы с временем работы описываемых алгоритмов и FGb на трех сериях. 
В некоторых случаях в таблице стоит прочерк, что означает, что программа либо работает дольше разумного предела ожидания, 
либо не может отработать в связи с внутренними ограничениями (FGb начиная с cyclic13). 

\medskip

\begin{center}
\begin{tabular}{|l|r|r|r|}
	\hline
	\multicolumn{4}{|c|}{Cyclic}\\
	\hline
	Тест&PackedBuhberger&PackedF4&FGb 1.34\\
	\hline
  cyclic8&0.062&0.219&0.061\\
  cyclic9&0.156&0.141&0.203\\
  cyclic10&0.640&3.859&1.437\\
  cyclic11&1.609&1.500&9.328\\
  cyclic12&7.766&119.238&80.359\\
  cyclic13&18.844&-&-\\
  cyclic14&108.063&-&-\\
  cyclic15&305.422&-&-\\
  \hline
\end{tabular}
\end{center}

\medskip

\begin{center}
\begin{tabular}{|l|r|r|r|}
	\hline
	\multicolumn{4}{|c|}{Eco}\\
	\hline
	Тест&PackedBuhberger&PackedF4&FGb 1.34\\
	\hline
  eco8&0.031&0.078&0.062\\
  eco9&0.078&0.140&0.047\\
  eco10&0.187&0.469&0.109\\
  eco11&0.485&2.078&0.062\\
  eco12&0.985&4.843&0.062\\
  eco13&9.421&12.515&0.093\\
  eco14&34.078&13.812&0.094\\
  eco15&163.765&45.313&0.092\\
  \hline
\end{tabular}
\end{center}

\medskip

\begin{center}
\begin{tabular}{|l|r|r|r|}
 	\hline
 	\multicolumn{4}{|c|}{Katsura}\\
 	\hline
 	Тест&PackedBuhberger&PackedF4&FGb 1.34\\
 	\hline
  katsura8&0.000&0.000&0.062\\
  katsura9&0.000&0.000&0.047\\
  katsura10&0.000&0.000&0.062\\
  katsura11&0.000&0.000&0.061\\
  katsura12&0.000&0.000&0.062\\
  katsura13&0.000&0.000&0.094\\
  katsura14&0.000&0.000&0.062\\
  katsura15&0.000&0.000&0.062\\
  \hline
\end{tabular}
\end{center}

\medskip


\subsection*{Параллельная версия}

Исследование показало, что при достаточном увеличении размера задачи на стандартных примерах специфическая реализация начинает 
обгонять по времени общую реализацию F4 при запуске на одном процессоре. 
Кроме того, выясняется, что в случае $F_2$ операция приведения матрицы к ступенчатому виду уже не занимает $99\%$ всего времени работы алгоритма, 
как было в случае общей реализации F4, а занимает порядка $30-60\%$ на одном процессоре, 
однако другие операции, нераспараллеленные, начинают занимать более существенную часть времени. 
Соответственно, при запуске на нескольких процессорах специфическая для $F_2$ версия алгоритма начинает проигрывать общей, 
так как в ней распараллелена только операция приведения матрицы к ступенчатому виду, 
но с другой стороны появляется возможность общего ускорения засчет распараллеливания и других основных частей алгоритма.

За основу параллельной версии программы были взяты те же спецефические структуры данных, что и в последовательной версии, 
а распараллеливаемая часть является общей с основной реализацией параллельного F4.

Запуск программы на тестовых примерах из серий \verb|cyclic|, \verb|hcyclic|, \verb|extcyc|, \verb|redcyc| показал, 
что на тестовых примерах маленького размера специфическая реализация немного проигрывает по времени 
общей в силу менее эффективных операций над многочленами. 
Однако при увеличении размера задачи при запуске на одном процессоре специфическая реализация начинает работать быстрее, 
и уже при временах порядка десятков секунд начинает выигрывать по времени, 
а на следующем порядке задачи выигрыш еще увеличивается.

В то время, как приведение матрицы к ступенчатому виду в случае общей реализации занимает более $90\%$ всего времени работы программы, 
в случае специфического алгоритма для поля $F_2$ ситуация сильно меняется: 
приведение матрицы к ступенчатому виду занимает порядка $30-60$ процентов времени при запуске на одном процессе. 
С одной стороны, благодаря этому общая реализация гораздо сильнее ускоряется при увеличении числа процессов, 
так как только этот этап и распараллелен. 
С другой стороны, задача приведения матрицы к ступенчатому виду сама по себе распараллеливается сравнительно плохо. 
Соответственно, если этот этап становится существенно быстрее сам по себе, то есть шанс, что распараллеливание всей программы целиком, 
а не только матричной части, даст здесь выигрыш.
 

\subsection*{Тестирование на одном процессоре}

Тестирование проводилось на машине Intel Pentium 2.13 GHz, 2GB RAM. 
Времена работы программ указаны в секундах. 
В двух последних столбцах показана доля суммарного времени работы метода Гаусса по приведению матриц к ступенчатому виду.

\medskip

\begin{center}
\begin{tabular}{|r|r|r|r|r|}
	\hline
	Тест&F4&F4F2&F4 Gauss&F4F2 Gauss\\
	\hline
	cyclic12&26.70&19.08&22.08 (83\%)&7.21 (38\%)\\
	\hline
	cyclic13&260.88&102.89&245.33 (94\%)&54.01 (53\%)\\
	\hline
	hcyclic12&29.16&24.53&23.62 (81\%)&9.11 (37\%)\\
	\hline
	hcyclic13&258.36&142.89&241.11 (91\%)&74.44 (53\%)\\
	\hline
	redcyc13&23.00&25.14&18.53 (81\%)&8.96 (36\%)\\
	\hline
	redcyc14&331.45&197.75&310.29 (94\%)&111.95 (57\%)\\
	\hline
	extcyc12&20.61&23.31&16.62 (81\%)&8.22 (35\%)\\
	\hline
	extcyc13&774.99&210.83&736.97 (95\%)&133.88 (64\%)\\
	\hline
\end{tabular}
\end{center}


\medskip

Результаты показывают, что, во-первых, алгоритмы, учитывающие специфику поля $F_2$, 
работают существенно быстрее (кроме <<простых>> тестовых примеров \verb|redcyc13| и \verb|extcyc13|, 
на которых имеется несущественный проигрыш). 
Во-вторых, доля именно матричных вычислений в специфическом алгоритме уменьшается по сравнению с обычной версией.
 
\subsection*{Тестирование на нескольких процессорах}

В таблице приведены данные о запуске программы на некоторых тестовых примерах, на $1, 2, 4$ и $8$ процессорах соответственно. 
В каждой ячейке приведено общее время работы программы и время в секундах, 
затраченное на приведение матрицы к ступенчатому виду (единственная распаралеленная часть на данный момент).

\medskip

\begin{center}
\begin{tabular}{|r|l|l|l|l|}
	\hline
	Тест&1 процессор&2 процессора&4 процессора&8 процессоров\\
	\hline
	cyclic14&613 / 360&460 / 190&380 / 109&350 / 75\\
	\hline
	hcyclic13&146 / 71&108 / 37&96 / 24&90 / 18\\
	\hline
	hcyclic14&843 / 480&621 / 247&493 / 128&485 / 119\\
	\hline
	redcyc14&201 / 105&150 / 50&135 / 36&133 / 30\\
	\hline
	redcyc15&871 / 523&635 / 282&541 / 192&491 / 147\\
	\hline
\end{tabular}
\end{center}

\medskip

Отсюда видим, что матричная часть действительно распараллеливается, но занимает она далеко не все процессорное время, 
а время на выполнение остальных функций (в основном это \verb|Preprocess| и \verb|Update|) практически не меняется. 
Следовательно, потенциальное ускорение этого алгоритма  можно получить из распараллеливания этих функций.
 
 
\subsection*{Программный код реализации основных операций над мономами}
Ниже приведены комментарии к реализации важнейших операций.
{
\small
\begin{verbatim}

// Моном хранится как целочисленный вектор:
vector<unsigned int> monom;

// Получение степени монома:
int Cmonomial::getDegree() {
  int res = 0;
  for(int i = 0; i < monom.size(); i++)
    res += CmonomialUtilities::getBitCount(monom[i]);
  return res;
}

vector<char>* CMonomialUtilities::integerBitCounts(NULL);

void CMonomialUtilities::initBitCounts() {
  integerBitCounts = new vector<char>;
  integerBitCounts->resize(1 << 16);
  integerBitCounts->at(0) = 0;
  for (int i = 1; i < (1 << 16); i++)
    integerBitCounts->at(i) = 
      integerBitCounts->at(i >> 1) + (i & 1);
}

int CMonomialUtilities::getBitCount(unsigned int a) {
  return integerBitCounts->at(a >> 16) + 
    integerBitCounts->at(a & ((1 << 16) - 1));
}

// Умножение двух мономов:
void operator*= (const CMonomial& givenMonomial) {
  for(int i = 0; i < monom.size(); i++)
    monom[i] |= givenMonomial.monom[i];
}

// Проверка делимости монома на моном:
bool divisibleBy(const CMonomial& m) const {
  for(int i = 0; i < monom.size(); i++)
    if((monom[i] & m.monom[i]) != m.monom[i])
      return false;
  return true;
}

// Вычисление частного при делении монома на моном 
// (предполагается, что проверка делимости уже произведена):
void operator/= (const CMonomial& givenMonomial) {
  for(int i = 0; i < monom.size(); i++)
    monom[i] ^= givenMonomial.monom[i];
}


// Вычисление наименьшего общего кратного двух мономов:
static const CMonomial lcm (
    const CMonomial& firstMonomial,
    const CMonomial& secondMonomial
) {
  CMonomial res;
  for(int i = 0; i < firstMonomial.monom.size(); i++)
  res.monom[i] = firstMonomial.monom[i] |
    secondMonomial.monom[i];
  return res;
}
\end{verbatim}
}



\section*{Благодарности}

Коллектив авторов благодарит руководителя проекта
д.~ф.-м.~н., профессора А.~В. Михалева. 
Авторы выражают глубокую признательность 
А. М. Чеповскому и А. А. Михалеву,
а также П.~Наливайко.

Работа посвящается нашему научному руководителю Евгению Васильевичу Панкратьеву, трагически погибшему 23 января 2008 года.



\begin{thebibliography}{99}

\bibitem{AttardiTraverso}
 Attardi G. and Traverso C. 
 \Title{A strategy-accurate parallel Buchberger algorithm}
 // Proceedings of PASCO 1994, World Scientific Publ. Comp. 

\bibitem{BW}
 Becker T. and Weispfenning V. 
 \Title{Gr\"obner Bases. A Computational Approach to Commutative Algebra} 
 // Graduate Texts in Mathematics, Springer-Verlag, New York, 1993.

\bibitem{Buchberger}
 Buchberger B. 
 \Title{Gr\"obner Bases: an Algorithmic Method in Polynomial Ideal Theory}
 // Multidimensional Systems Theory, pp. 184--232. U. Reidel Publishing Company, 1985.

\bibitem{FaugereParallel}
 Faugere J.-C. 
 \Title{Parallelization of Gr\"obner Bases}
 // Proceedings of PASCO 1994, World Scientific Publ. Comp.

\bibitem{F4}
 Faug\`ere J.-C. 
 \Title{A new efficient algorithm for computing Gr\"obner bases (F4)}
 // Journal of Pure and Applied Algebra, 139 (1--3): 61--88, 1999.

\bibitem{F5}
 Faugere J.-C. 
 \Title{A new efficient algorithm for computing Gr\"obner bases without reduction to zero (F5)} 
 // Proceedings of the 2002 International Symposium on Symbolic and Algebraic Computation (ISSAC), 75--83. 
    ACM Press, 2002.


\bibitem{GebauerMoeller}
 Gebauer R. and M\"{o}ller H. M. 
 \Title{On an Installation of Buchberger's Algorithm}
 // J. Symbolic Computation, 1988, 6, 275--286.

\bibitem{Gerdt}
 Gerdt V. P. 
 \Title{Gr\"obner bases and involutive methods for algebraic and differential equations}
 // Mathematics and Computers in Modeling, 25, No. 8/9, 1997, 75--90. 

\bibitem{GerdtParallel}
 Gerdt V. P. and Yanovich D. A. 
 \Title{Parallel Computation of Involutive and Gr\"obner Bases}
 // Proceedings of CASC 2003, V.G.Ganza, E.W.Mayr, and E.V. Vorozhtsov, eds. Institute of Informatics, Technical University of Munich, Garching, 2004, pp. 185-194.

% \bibitem{GerdtZinin}
%  Gerdt V. and Zinin M. 
%  \Title{On Computation of Gr\"obner Basis over $F_2$}
%  // Принято к печати в журнале <<Программирование>>, 2008.

\bibitem{HFE}
 Kipnis A. and Shamir A. 
 \Title{Cryptanalysis of the HFE Public Key Cryptosystem by Relinearization}
  // Advances in Cryptology~--- Crypto'99, vol. 1666 of LNCS, pp. 19--30. Springer-Verlag, 1999.

\bibitem{Syzygies}
 Moller H. M., Mora T., Traverso C. 
 \Title{Gr\"obner bases computation using syzygies}
 // Proc. of ISSAC 1992. 

\bibitem{Segers}
 Segers A. J. M.
 \Title{Algebraic Attacks from a Gr\"obner bases perspective}
 // 2004.

\bibitem{Stegers}
 Stegers T.
 \Title{Faugere's F5 algorithm revisited}
 // Department Of Mathematics, Technische Universitat Darmstadt, 2005.
 
\bibitem{Tran}
 Qu\^oc-Nam Tr\^an.
 \Title{Parallel computation and Gr\"obner bases: an application for converting bases with the Gr\"obner walk}
 // Gr\"obner bases and applications, Cambridge University Press, 1998.
 
\bibitem{Reeves}
 Reeves A. A. 
 \Title{A Parallel Implementation of Buchberger's Algorithm over $\Z_p$ for $p = 31991$} 
 // J. Symbolic Computation, 1998, 229--244. 
 
\bibitem{Roune}
 Roune B. H.
 \Title{The F4 algorithm: speeding up Gr\"obner basis computation using linear algebra}
 // 2005.

\bibitem{Yanovich}
 Yanovich D.A. 
 \Title{Parallelization of an Algorithm for Computation of Involutive Janet Bases}
 // Programming and Computer Software, vol.~28, No.~2, 2002.

\bibitem{GerdtZinin}
 Гердт В. П., Зинин М. В.
 \Title{Инволютивный метод вычисления базисов Гребнера над $F_2$}
 // Программирование, № 4 (2008), стр. 8--24.

\bibitem{JanetTree}
 Гердт В. П., Янович Д. А., Блинков Ю. А.
 \Title{Быстрый поиск делителя Жане}
 // Программирование, № 1 (2001), стр. 32--36.

\bibitem{Cox}
 Кокс Д., Литтл Дж., О'Ши Д.
 \Title{Идеалы, многообразия и алгоритмы}
 // М., Мир, 2000.
%  Cox D., Little J., O’Shea D. 
%  \Title{Ideals, Varieties and Algorithms. An Introduction to Computational Algebraic Geometry and Commutative Algebra}
%  // New York, NY: Springer, 1998

\bibitem{MityuninPankratiev}
 Митюнин В. А., Панкратьев Е. В. 
 \Title{Параллельные алгоритмы построения базисов Гребнера}
 // Международная алгебраическая конференция, тезисы докладов, Москва, механико-математический факультет МГУ, 2004, стр. 97--99.

\bibitem{Pankratiev}
 Панкратьев Е. В.
 \Title{Элементы компьютерной алгебры}
 // М., Бином, 2007.
 
\bibitem{Yanovich2}
 Янович Д. А.
 \Title{Оценка эффективности распределенных вычислений базисов Гребнера и инволютивных базисов}
 // Программирование, № 4 (2008), стр. 32--40.

\end{thebibliography}
\end{document}
